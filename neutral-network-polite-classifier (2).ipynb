{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7606187,"sourceType":"datasetVersion","datasetId":4428468},{"sourceId":7614628,"sourceType":"datasetVersion","datasetId":4434421},{"sourceId":1246668,"sourceType":"datasetVersion","datasetId":715814}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Embedding, GlobalAveragePooling1D\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-13T00:36:15.780115Z","iopub.execute_input":"2024-02-13T00:36:15.780604Z","iopub.status.idle":"2024-02-13T00:36:15.786263Z","shell.execute_reply.started":"2024-02-13T00:36:15.780574Z","shell.execute_reply":"2024-02-13T00:36:15.785314Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"\ndf = pd.read_csv(\"/kaggle/input/politeness-train/politeness_train.csv\")\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:36:20.115269Z","iopub.execute_input":"2024-02-13T00:36:20.115700Z","iopub.status.idle":"2024-02-13T00:36:20.143723Z","shell.execute_reply.started":"2024-02-13T00:36:20.115669Z","shell.execute_reply":"2024-02-13T00:36:20.142644Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"   utterance_id  conversation_id  \\\n0          3208             2099   \n1          4458             4622   \n2          4888             5599   \n3          3316             2295   \n4          4005             3674   \n\n                                                text  polite  \n0  Is it for a particular CPU (e.g. a Z80 or the ...       1  \n1  What is an eastern style pot?  Is this a cup-l...       1  \n2  I didn't know that you had to use an email add...       0  \n3  I don't understand.  That call stack is all ab...       1  \n4  The last sentence makes me think that there is...       0  \n","output_type":"stream"}]},{"cell_type":"code","source":"df.polite.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-02-12T23:40:51.116497Z","iopub.execute_input":"2024-02-12T23:40:51.116944Z","iopub.status.idle":"2024-02-12T23:40:51.126513Z","shell.execute_reply.started":"2024-02-12T23:40:51.116912Z","shell.execute_reply":"2024-02-12T23:40:51.124902Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"polite\n1    2457\n0    2457\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.count()\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:39:15.686245Z","iopub.execute_input":"2024-02-13T00:39:15.686783Z","iopub.status.idle":"2024-02-13T00:39:15.697232Z","shell.execute_reply.started":"2024-02-13T00:39:15.686747Z","shell.execute_reply":"2024-02-13T00:39:15.696076Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"utterance_id       4914\nconversation_id    4914\ntext               4914\npolite             4914\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"\nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import WhitespaceTokenizer\nfrom nltk.stem import WordNetLemmatizer\n\ndef clean_text(text):\n    # lower text\n    text = text.lower()\n    # tokenize text and remove puncutation\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # remove words that contain numbers\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # remove stop words\n    stop = stopwords.words('english')\n    text = [x for x in text if x not in stop]\n    # remove empty tokens\n    text = [t for t in text if len(t) > 0]\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n    # remove words with only one letter\n    text = [t for t in text if len(t) > 1]\n    # join all\n    text = \" \".join(text)\n    return(text)\n\n# clean text data\ndf[\"text\"] = df[\"text\"].apply(lambda x: clean_text(x))","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:40:10.371837Z","iopub.execute_input":"2024-02-13T00:40:10.372767Z","iopub.status.idle":"2024-02-13T00:40:11.306247Z","shell.execute_reply.started":"2024-02-13T00:40:10.372734Z","shell.execute_reply":"2024-02-13T00:40:11.305037Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:40:16.139065Z","iopub.execute_input":"2024-02-13T00:40:16.139516Z","iopub.status.idle":"2024-02-13T00:40:16.151188Z","shell.execute_reply.started":"2024-02-13T00:40:16.139473Z","shell.execute_reply":"2024-02-13T00:40:16.149463Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"   utterance_id  conversation_id  \\\n0          3208             2099   \n1          4458             4622   \n2          4888             5599   \n3          3316             2295   \n4          4005             3674   \n\n                                                text  polite  \n0  particular cpu e.g cell processor's spu abstra...       1  \n1  eastern style pot cup-like device lid strain l...       1  \n2     know use email address instead username change       0  \n3  understand call stack debug help library happe...       1  \n4  last sentence makes think bigger picture reall...       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>utterance_id</th>\n      <th>conversation_id</th>\n      <th>text</th>\n      <th>polite</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3208</td>\n      <td>2099</td>\n      <td>particular cpu e.g cell processor's spu abstra...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4458</td>\n      <td>4622</td>\n      <td>eastern style pot cup-like device lid strain l...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4888</td>\n      <td>5599</td>\n      <td>know use email address instead username change</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3316</td>\n      <td>2295</td>\n      <td>understand call stack debug help library happe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4005</td>\n      <td>3674</td>\n      <td>last sentence makes think bigger picture reall...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['text'])\nsequences = tokenizer.texts_to_sequences(df['text'])\nX = pad_sequences(sequences, maxlen=100)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:40:48.749208Z","iopub.execute_input":"2024-02-13T00:40:48.749674Z","iopub.status.idle":"2024-02-13T00:40:48.956026Z","shell.execute_reply.started":"2024-02-13T00:40:48.749634Z","shell.execute_reply":"2024-02-13T00:40:48.954762Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"y = df['polite'].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:41:13.716686Z","iopub.execute_input":"2024-02-13T00:41:13.717117Z","iopub.status.idle":"2024-02-13T00:41:13.731142Z","shell.execute_reply.started":"2024-02-13T00:41:13.717083Z","shell.execute_reply":"2024-02-13T00:41:13.729306Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nwith open('/kaggle/input/glove6b100dtxt/glove.6B.100d.txt', encoding='utf-8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:45:50.299535Z","iopub.execute_input":"2024-02-13T00:45:50.300169Z","iopub.status.idle":"2024-02-13T00:46:01.380158Z","shell.execute_reply.started":"2024-02-13T00:45:50.300138Z","shell.execute_reply":"2024-02-13T00:46:01.378943Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# Create embedding matrix\nword_index = tokenizer.word_index\nnum_words = min(len(word_index) + 1, len(embeddings_index))\nembedding_dim = 100\nembedding_matrix = np.zeros((num_words, embedding_dim))\nfor word, i in word_index.items():\n    if i >= num_words:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:46:27.931494Z","iopub.execute_input":"2024-02-13T00:46:27.931982Z","iopub.status.idle":"2024-02-13T00:46:27.963479Z","shell.execute_reply.started":"2024-02-13T00:46:27.931947Z","shell.execute_reply":"2024-02-13T00:46:27.962219Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"# Build the neural network model\nmodel = Sequential()\nmodel.add(Embedding(num_words, embedding_dim, weights=[embedding_matrix], input_length=100, trainable=False))\nmodel.add(GlobalAveragePooling1D())\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-13T00:54:06.131287Z","iopub.execute_input":"2024-02-13T00:54:06.131717Z","iopub.status.idle":"2024-02-13T00:54:06.209160Z","shell.execute_reply.started":"2024-02-13T00:54:06.131687Z","shell.execute_reply":"2024-02-13T00:54:06.207988Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(X_train, y_train, epochs=10, verbose=2, validation_data=(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2024-02-13T01:09:28.160631Z","iopub.execute_input":"2024-02-13T01:09:28.161098Z","iopub.status.idle":"2024-02-13T01:09:34.103256Z","shell.execute_reply.started":"2024-02-13T01:09:28.161064Z","shell.execute_reply":"2024-02-13T01:09:34.101171Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"Epoch 1/10\n123/123 - 1s - loss: 0.6089 - accuracy: 0.6688 - val_loss: 0.6427 - val_accuracy: 0.6287 - 1s/epoch - 11ms/step\nEpoch 2/10\n123/123 - 0s - loss: 0.6062 - accuracy: 0.6678 - val_loss: 0.6392 - val_accuracy: 0.6419 - 375ms/epoch - 3ms/step\nEpoch 3/10\n123/123 - 0s - loss: 0.6041 - accuracy: 0.6698 - val_loss: 0.6401 - val_accuracy: 0.6368 - 379ms/epoch - 3ms/step\nEpoch 4/10\n123/123 - 0s - loss: 0.6026 - accuracy: 0.6762 - val_loss: 0.6406 - val_accuracy: 0.6277 - 381ms/epoch - 3ms/step\nEpoch 5/10\n123/123 - 0s - loss: 0.6031 - accuracy: 0.6726 - val_loss: 0.6423 - val_accuracy: 0.6358 - 442ms/epoch - 4ms/step\nEpoch 6/10\n123/123 - 0s - loss: 0.6010 - accuracy: 0.6734 - val_loss: 0.6428 - val_accuracy: 0.6277 - 389ms/epoch - 3ms/step\nEpoch 7/10\n123/123 - 0s - loss: 0.6008 - accuracy: 0.6759 - val_loss: 0.6400 - val_accuracy: 0.6307 - 366ms/epoch - 3ms/step\nEpoch 8/10\n123/123 - 0s - loss: 0.5989 - accuracy: 0.6800 - val_loss: 0.6389 - val_accuracy: 0.6378 - 369ms/epoch - 3ms/step\nEpoch 9/10\n123/123 - 0s - loss: 0.5980 - accuracy: 0.6764 - val_loss: 0.6388 - val_accuracy: 0.6328 - 370ms/epoch - 3ms/step\nEpoch 10/10\n123/123 - 0s - loss: 0.5968 - accuracy: 0.6797 - val_loss: 0.6416 - val_accuracy: 0.6338 - 372ms/epoch - 3ms/step\n","output_type":"stream"},{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7b324674e560>"},"metadata":{}}]},{"cell_type":"code","source":"y_pred_prob = model.predict(X_test)\ny_pred = (y_pred_prob > 0.5).astype(int)\n\nreport = classification_report(y_test, y_pred)\n\nprint(\"Classification Report:\")\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2024-02-13T01:10:00.314925Z","iopub.execute_input":"2024-02-13T01:10:00.315458Z","iopub.status.idle":"2024-02-13T01:10:00.608556Z","shell.execute_reply.started":"2024-02-13T01:10:00.315424Z","shell.execute_reply":"2024-02-13T01:10:00.607301Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"31/31 [==============================] - 0s 2ms/step\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.64      0.59      0.61       482\n           1       0.63      0.68      0.65       501\n\n    accuracy                           0.63       983\n   macro avg       0.63      0.63      0.63       983\nweighted avg       0.63      0.63      0.63       983\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SUMMARY**\n*Accuracy is at 63% which is less than that of logistic regression classifier.* \n\n* Glove Embeddings is used because of their effectiveness in capturing global word co-occurence which is better representation of word semantics.\n* Word sequence preserves the sequential information present in the text, allowing the neural network to learn from the order of words in sentences.\n* Epochs is to 10 because dataset size is not very large hence set epoch to a smaller value\n* Set verbose to 2 to control verbosity during training to avoid excessive verbosity that might clutter the input\n","metadata":{}}]}